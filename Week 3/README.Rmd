---
title: '`Week 3` Regression Models'
author: '`r if(knitr::is_html_output()) {"&#x1f468;&#x1F3FB;&#x200d;&#x1f4bb; Anderson H Uyekita"} else {NULL}`'
output:
  github_document: default
params:
  author: 'Anderson H Uyekita'
  course: 'Regression Models'
  course_url: 'https://www.coursera.org/learn/regression-models'
  specialization: 'Data Science: Foundations using R Specialization'
  specialization_url: 'https://www.coursera.org/specializations/data-science-foundations-r'
  instructor: 'Brian Caffo'
  course_start: !r lubridate::ymd('2022/07/05', tz = 'America/Sao_Paulo')
  course_finish: !r lubridate::today(tzone = "America/Sao_Paulo")
  week: ' Week 3'
---

```{r setup,include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE)
library(rmarkdown)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(magrittr)
library(datasets)
library(UsingR)
```

`r if(!knitr::is_html_output()) {sprintf(fmt = "* &#x1f468;&#x1F3FB;&#x200d;&#x1f4bb; Author: %s", params$author)}`
`r sprintf(fmt = "* &#x1f4da; Specialization: [%s](%s){target='_blank' rel='noopener'}", params$specialization, params$specialization_url)`
`r sprintf(fmt = "* &#x1f4d6; Course: [%s](%s){target='_blank' rel='noopener'}", params$course, params$course_url)`
    `r sprintf(fmt = "* &#x1F9D1;&#x200d;&#x1F3EB; Instructor: %s", params$instructor)`
`r sprintf(fmt = "* &#x1F4C6; %s", params$week)`
    `r sprintf(fmt = "* &#x1F6A6; Start: %s", format(params$course_start, "%A, %d %B %Y"))`
    `r sprintf(fmt = "* &#x1F3C1; Finish: %s", format(params$course_finish, "%A, %d %B %Y"))`

--------------------------------------------------------------------------------

#### Assignments & Deliverables

* [&#x1F680; Course Project 3 Repository](https://github.com/AndersonUyekita/regression-models_course-project-3)
* [&#x1F4DD; Quiz 3](./quiz-3_regression-models.md)

#### Slides

* Module 3 -- Multivariable Regression, Residuals, & Diagnostics
    * 03_01 GLMs
    * 03_02 Binary outcomes
    * 03_03 Count outcomes
    * 03_04 Olio

#### Description

> This week, we'll build on last week's introduction to multivariable regression with some examples and then cover residuals, diagnostics, variance inflation, and model comparison.

--------------------------------------------------------------------------------

## Class Notes

#### Multivariable regression

>We now extend linear regression so that our models can contain more variables. A natural first approach is to assume additive effects, basically extending our line to a plane, or generalized version of a plane as we add more variables.  Multivariable regression represents one of the most widely used and successful methods in statistics.  

> The interpretation of a multivariate regression coefficient is the expected change in the
response per unit change in the regressor, holding all of the other regressors fixed.

##### Example

Multivariate using `Seatbelts` dataset.

```{r}
# Loading Seatbelts dataset
library(datasets)

# Creating a object.
df <- as_tibble(datasets::Seatbelts)

# Fitting the model
fit <- lm(data = df, formula = DriversKilled ~ kms + PetrolPrice)

# Printing the coefficients results.
round(summary(fit)$coeff, 4)
```

All parameters have **rejected** the $H_0$ hypothesis. However, it lacks interpretation because the expected number of 215 drivers killed when the `kms` and `PetroPrice` are equal to zero has no sense.

##### Adjusting the data

Creating a meaningful model.

```{r}
# Loading Seatbelts dataset
library(datasets)

# Creating a object.
df <- as_tibble(datasets::Seatbelts)

# Centering the dataset.
df$kms_avg <- df$kms - mean(df$kms)
df$petrol_avg <- (df$PetrolPrice - mean(df$PetrolPrice))/sd(df$PetrolPrice)

# Adding new variables to the dataset.
kms_avg <- mean(df$kms)
petrol_avg <- mean(df$PetrolPrice)

# Fitting the model
fit <- lm(data = df, formula = DriversKilled ~ kms_avg + petrol_avg)

# Printing the coefficients results.
summary(fit)$coeff
```

* The intercept of 122.8 is the estimated number of `DriversKilled` for the average `PetroPrice` and average `kms`;
* The `PetroPrice` negative 7.9 means we expect less 7.9 `DriversKilled` per **one standard deviation** change in `PetroPrice`, and;
* Maintaining the other variables constant, the negative 0.017 in average `kms` means we expect less 0.0017 `DriversKilled` per `kms`, It is counter intuitive because increasing the `kms` reduces the drivers killed.

It is also possible to scale `kms` to analyze it in thousands.

```{r}
# Loading Seatbelts dataset
library(datasets)

# Creating a object.
df <- as_tibble(datasets::Seatbelts)

# Centering the dataset.
df$kms_avg <- (df$kms - mean(df$kms))/1000
df$petrol_avg <- (df$PetrolPrice - mean(df$PetrolPrice))/sd(df$PetrolPrice)

# Adding new variables to the dataset.
kms_avg <- mean(df$kms)
petrol_avg <- mean(df$PetrolPrice)

# Fitting the model
fit <- lm(data = df, formula = DriversKilled ~ kms_avg + petrol_avg)

# Printing the coefficients results.
summary(fit)$coeff
```
* After the scaling, we expect less 1.75 `DriversKilled` per 1000 `kms`.
